{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a0dfb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.52.1-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.7.0-cp311-cp311-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\python311\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\python311\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.31.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-11.2.1-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\python311\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.9.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.0)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.28.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.24.2)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2022.12.7)\n",
      "Using cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Using cached huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
      "Using cached torch-2.7.0-cp311-cp311-win_amd64.whl (212.5 MB)\n",
      "Using cached transformers-4.52.1-py3-none-any.whl (10.5 MB)\n",
      "Using cached pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "Using cached fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: safetensors, regex, pyyaml, Pillow, networkx, fsspec, torch, huggingface-hub, tokenizers, transformers, sentence-transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~%p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~0p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~1p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~2p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~3p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~4p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~5p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~%p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~0p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~1p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~2p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~3p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~4p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~5p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python311\\Lib\\site-packages)\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] Le fichier spécifié est introuvable: 'c:\\\\Python311\\\\Scripts\\\\torchfrtrace.exe' -> 'c:\\\\Python311\\\\Scripts\\\\torchfrtrace.exe.deleteme'\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87edfe25",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0350ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df = pd.read_csv(\"Data/profile_model.csv\").fillna(\"\")\n",
    "offers_df = pd.read_csv(\"Data/offres_model.csv\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b93529",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offres = offers_df.copy()\n",
    "df_offres['offre_id'] = df_offres.index  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdfc2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidats = profiles_df.copy()\n",
    "df_candidats['candidat_id'] = df_candidats.index  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4520602",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"Metier_regroupe\": 0.20,\n",
    "    \"Points_forts\": 0.15,\n",
    "    \"Compétence\": 0.15,\n",
    "    \"Contrat\": 0.15,\n",
    "    \"Experience_mois\": 0.20,\n",
    "    \"Departement\": 0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edd07eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_map = {\n",
    "    \"Metier_regroupe\": \"groupe_metier\",\n",
    "    \"Points_forts\": \"stack_technique\",\n",
    "    \"Compétence\": \"stack_technique\",\n",
    "    \"Contrat\": \"Contrat\",\n",
    "    \"Experience_mois\": \"experience_mois\",\n",
    "    \"Departement\": \"Departement\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7072e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd8b002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_total = np.zeros((len(profiles_df), len(offers_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeee3674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 22/22 [00:02<00:00,  8.13it/s]\n",
      "Batches: 100%|██████████| 70/70 [00:05<00:00, 13.42it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:07<00:00,  2.94it/s]\n",
      "Batches: 100%|██████████| 70/70 [00:58<00:00,  1.20it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:18<00:00,  1.21it/s]\n",
      "Batches: 100%|██████████| 70/70 [00:58<00:00,  1.19it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:01<00:00, 13.58it/s]\n",
      "Batches: 100%|██████████| 70/70 [00:04<00:00, 15.70it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:01<00:00, 13.52it/s]\n",
      "Batches: 100%|██████████| 70/70 [00:04<00:00, 16.47it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:01<00:00, 20.41it/s]\n",
      "Batches: 100%|██████████| 70/70 [00:09<00:00,  7.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for profile_field, weight in weights.items():\n",
    "    \n",
    "    offer_field = field_map[profile_field]\n",
    "    profile_texts = profiles_df[profile_field].astype(str).tolist()\n",
    "    offer_texts = offers_df[offer_field].astype(str).tolist()\n",
    "\n",
    "    profile_embeddings = model.encode(profile_texts, show_progress_bar=True)\n",
    "    offer_embeddings = model.encode(offer_texts, show_progress_bar=True)\n",
    "\n",
    "    sim_matrix = cosine_similarity(profile_embeddings, offer_embeddings)\n",
    "\n",
    "    similarity_total += weight * sim_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27750aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_matches = []\n",
    "for i in range(similarity_total.shape[0]):\n",
    "    best_offer_index = np.argmax(similarity_total[i])\n",
    "    best_score = similarity_total[i, best_offer_index]\n",
    "    best_matches.append((i, best_offer_index, best_score))\n",
    "\n",
    "df_scores = best_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a79ed7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1         2\n",
      "0      0  1016  0.805999\n",
      "1      1   996  0.766454\n",
      "2      2  1050  0.769109\n",
      "3      3   860  0.785300\n",
      "4      4  1226  0.739943\n",
      "..   ...   ...       ...\n",
      "684  684  1044  0.802468\n",
      "685  685  2072  0.858333\n",
      "686  686  1591  0.816042\n",
      "687  687  1813  0.655739\n",
      "688  688  1680  0.777547\n",
      "\n",
      "[689 rows x 3 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(df_scores)\n",
    "print(type(df_scores))  # Debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6fe656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(best_matches, columns=['candidat_id', 'offre_id', 'score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83a3e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = df_scores.merge(df_candidats, left_on='candidat_id', right_on='candidat_id', how='left')\n",
    "df_scores = df_scores.merge(df_offres, on='offre_id', how='left', suffixes=('_candidat', '_offre'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "651c6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "candidats_meilleures_offres = (\n",
    "    df_scores\n",
    "    .sort_values(by=['candidat_id', 'score'], ascending=[True, False])\n",
    "    .groupby('candidat_id')\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36c698f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidats_meilleures_offres = candidats_meilleures_offres[\n",
    "    ['candidat_id', 'Profil', 'Points_forts', 'Compétence', 'Expérience', 'Nom_poste','Contrat_offre', 'Description',\n",
    "       'Experience', 'Entreprise', 'score']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e77009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55f64e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     candidat_id                                             Profil  \\\n",
      "0              0                                     Data Scientist   \n",
      "1              1  Information Security Management | Digital Tran...   \n",
      "2              2                            Actuaire / Data Analyst   \n",
      "3              3                                      Data engineer   \n",
      "4              4                                     data scientist   \n",
      "..           ...                                                ...   \n",
      "684          684                                    Actuaire Junior   \n",
      "685          685                             Consultante financière   \n",
      "686          686                                    Energy Engineer   \n",
      "687          687                        Chef de projet informatique   \n",
      "688          688        Developper intelligence artificielle junior   \n",
      "\n",
      "                                          Points_forts  \\\n",
      "0    Application des méthodes de machine learning d...   \n",
      "1    Adapter les outils de traitement statistique d...   \n",
      "2    Développer des modèles mathématiques pour la c...   \n",
      "3                                                        \n",
      "4                                                        \n",
      "..                                                 ...   \n",
      "684                                                      \n",
      "685  Indicateurs de suivi dactivité Recueillir et a...   \n",
      "686  Concevoir et gérer un projet Définir les carac...   \n",
      "687  Animer coordonner une équipe Concevoir et gére...   \n",
      "688  Définir et faire évoluer des procédés de trait...   \n",
      "\n",
      "                                            Compétence  \\\n",
      "0    Application des méthodes de machine learning d...   \n",
      "1    Conception et analyse denquête Économie du dév...   \n",
      "2    Application des méthodes de machine learning d...   \n",
      "3    Application des méthodes de machine learning d...   \n",
      "4    Algorithmique Avancé Déploiement de services c...   \n",
      "..                                                 ...   \n",
      "684  Finance Gestion de bases de données NoSQL Avan...   \n",
      "685  Calculer les marges la rentabilité dun produit...   \n",
      "686  Concevoir larchitecture dun système dun réseau...   \n",
      "687  After Effects Intermédiaire CSS Avancé GitHub ...   \n",
      "688  Animer coordonner une équipe Caractéristiques ...   \n",
      "\n",
      "                                            Expérience  \\\n",
      "0    Stage de recherche de fin détude de Master II ...   \n",
      "1    Manager de la sécurité dinformation ODDO BHF S...   \n",
      "2    Actuaire Junior chez Swiss Life Prévoyance et ...   \n",
      "3    MSc BIHAR Big Data Intelligence for Human Augm...   \n",
      "4         ingénieur IA Groupe COVEA Niort France 5 Ans   \n",
      "..                                                 ...   \n",
      "684  Actuariat Bac5 et plus ou équivalentsCette For...   \n",
      "685  MS Audit et contrôle de gestion et système din...   \n",
      "686  Double diplome Management des sytèmes énergéti...   \n",
      "687  Assistant chargé de projet interne H3 hitema p...   \n",
      "688               Barman Restaurant Jardin dAsie 5 Ans   \n",
      "\n",
      "                                             Nom_poste Contrat_offre  \\\n",
      "0    Group Associate Expert Data & Analytics H/F - ...           CDD   \n",
      "1                                                                CDD   \n",
      "2                                 Data scientist (H/F)         Autre   \n",
      "3             DEV DATA ENGINEER (IT) / Freelance (H/F)           CDD   \n",
      "4    Data Scientist Référent F/H - Système, réseaux...           CDD   \n",
      "..                                                 ...           ...   \n",
      "684  Responsable Data (Achats) F/H - Projets scient...           CDD   \n",
      "685     Ingénieur Méthodes & Data Management F/H (H/F)           CDD   \n",
      "686            Analyste scientifique des données (H/F)           CDI   \n",
      "687               Chef de Projet Informatique/Data H/F           CDD   \n",
      "688                               INGENIEUR DATA (H/F)           CDD   \n",
      "\n",
      "                                           Description  \\\n",
      "0    Quelles seront vos missions en tant que Group ...   \n",
      "1    Selon votre parcours, vos expériences et votre...   \n",
      "2    Dans le cadre d?un projet stratégique mené pou...   \n",
      "3    Nous recherchons un profil confirmé de concept...   \n",
      "4    Descriptif du poste: Vous souhaitez travailler...   \n",
      "..                                                 ...   \n",
      "684  Descriptif du poste: En tant que consultant Ag...   \n",
      "685  VINCI FACILITIES ENERGILEC recrute un(e) Ingén...   \n",
      "686  Notre client, laboratoire pharmaceutique qui p...   \n",
      "687  Société en fort développement spécialisée dans...   \n",
      "688  Rejoignez nos équipes de la DSI : * Notre équi...   \n",
      "\n",
      "                          Experience       Entreprise     score  \n",
      "0       Expérience exigée de 2 An(s)                   0.805999  \n",
      "1       Expérience exigée de 3 An(s)               EY  0.766454  \n",
      "2       Expérience exigée de 5 An(s)            CELAD  0.769109  \n",
      "3       Expérience exigée de 4 An(s)                   0.785300  \n",
      "4       Expérience exigée de 5 An(s)           Natran  0.739943  \n",
      "..                               ...              ...       ...  \n",
      "684     Expérience exigée de 5 An(s)  AGILEBUYER SARL  0.802468  \n",
      "685  Expérience souhaitée de 1 An(s)     Groupe VINCI  0.858333  \n",
      "686                          5 An(s)    NUMAH CONSEIL  0.816042  \n",
      "687                 Débutant accepté                   0.655739  \n",
      "688     Expérience exigée de 5 An(s)       GROUPE SEB  0.777547  \n",
      "\n",
      "[689 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(candidats_meilleures_offres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "offres_meilleurs_candidats = (\n",
    "    df_scores\n",
    "    .sort_values(by=['offre_id', 'score'], ascending=[True, False])\n",
    "    .groupby('offre_id')\n",
    "    .head(5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c131bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "offres_meilleurs_candidats = offres_meilleurs_candidats[\n",
    "    ['offre_id', 'Nom_poste','Contrat_offre', 'Description',\n",
    "       'Experience', 'Entreprise', 'candidat_id', 'Profil', 'Points_forts', 'Compétence', 'Expérience', 'score']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2eedcb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "offres_meilleurs_candidats.to_excel(\"Data/offres_meilleurs_candidats.xlsx\", index=False)\n",
    "candidats_meilleures_offres.to_excel(\"Data/candidats_meilleures_offres.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
